
\newthought{Animal behavior} experiments require precision and repetition, which can best be achieved by computer automation. The complexity of contemporary behavioral experiments, however, presents a stiff methodological challenge. For example, researchers might wish to measure pupil dilation\citep{reimerPupilFluctuationsTrack2016, reimerPupilFluctuationsTrack2016}, respiration\citep{parabuckiOdorConcentrationChange2019}, and running speed\citep{niellModulationVisualResponses2010}, while tracking the positions of body parts in 3 dimensions\citep{nathUsingDeepLabCut3D2019} and recording the activity of large ensembles of neurons\citep{junFullyIntegratedSilicon2017}, as subjects perform tasks with custom input devices such as a steering wheel\citep{burgessHighYieldMethodsAccurate2017} while immersed in virtual reality environments using stimuli synthesized in real time\citep{thurleyVirtualRealitySystems2017,chambersOnlineStimulusOptimization2014}. Coordinating the array of necessary hardware into a coherent experimental design---with the millisecond precision required to study the brain---can be daunting.

Historically, researchers have developed software to automate behavior experiments as-needed within their lab or relied on purchasing proprietary software (eg. \citep{elliottNationalInstrumentsLabVIEW2007}). Open-source alternatives have emerged recently, often developed in tandem with hardware peripherals available for purchase \citep{ephysPyControl2019,sandersSanworksBPod}. However, the diverse hardware and software requirements for behavioral experiments often lead researchers to cobble together multiple tools to perform even moderately complex experiments. Indeed, most software packages do not attempt to simultaneously support custom hardware operation, behavioral task logic, stimulus generation, and data acquisition. Idiosyncratic systems can hinder reproducibility, especially if the level of detail reported in a methods section is sparse\citep{wallReliabilityStartsExperimental2019}. Additionally, development time and proprietary software are expensive, as are the custom hardware peripherals that are required to use most available open-source behavior software.
\vspace{12pt}

Here we present Autopilot, a complete open-source software and hardware framework for behavioral experiments. We leverage the power of distributed computing using the surprisingly capable Raspberry Pi 4\sidenote{See Table \ref{hwtab}} to allow researchers to coordinate arbitrary numbers of heterogeneous hardware components in arbitrary experimental designs.

Autopilot takes a different approach than existing systems to overcome the technical challenges of behavioral research: \textit{just use more computers}. Specifically, the advent of inexpensive single-board computers (ie. the Raspberry Pi) that are powerful enough to run a full Linux operating system allows a unified platform to run on every Pi or other computer in the system so that they can work together seamlessly. At the core of its architecture is a networking protocol (Section \ref{sec:networking}) that is fast enough to stream electrophysiological or imaging data and flexible enough to make the mutual coordination of hardware straightforward. 

This distributed design also makes Autopilot extremely scalable, as the Raspberry Pi's \$35 price tag makes it an order of magnitude less costly than comparable systems (Section \ref{sec:expense}). Its low cost doesn't come at the expense of performance or useability: Autopilot also has an order of magnitude greater measurement precision and an order of magnitude lower latency than comparable systems (Sections \ref{sec:lowlevel} and \ref{sec:tests}).

Autopilot balances experimental flexibility with support. Its task design infrastructure is flexible enough to perform arbitrary experiments, but also provides support for data management, plotting task progress, and custom training regimens. We provide a set of modular tools for users to easily build common tasks (such as the two-alternative forced choice task described in Section \ref{sec:tasks}), and have also written complete low-level API documentation to facilitate any tinkering needed to make Autopilot do whatever is needed. Rather than relying on costly proprietary hardware modules, users can take advantage of the wide array of peripherals and extensive community support available for the Raspberry Pi. 

Finally, we have designed Autopilot to do reproducible research. Experiments are not written as scripts that are reliant on the particularities of each researcher's hardware configuration. Instead, we have designed the system to encourage users to write reusable, portable experiments that are incorporated into a public central library. Every parameter that defines an experiment is automatically saved in  publication-ready format, removing ambiguity in reported methods and facilitating exact replication with a single file.

\vspace{12pt}

We\marginnote{We would like to acknowledge and thank Lucas Ott for doing much of the behavioral training, Brynna Paros and Nick Sattler for their help with constructing our behavioral boxes, Matt Smear and Reese Findley for loaning us their Bpod for far longer than they intended to, Erik Flister whose Ratrix software inspired some of the design features of Autopilot \citep{meierCollinearFeaturesImpair2011}, several artists on \url{flaticon.com} (\href{https://www.flaticon.com/authors/freepik}{Freepik}, \href{https://www.flaticon.com/authors/nikita-golubev}{Nikita Golubev}, \href{https://www.flaticon.com/authors/those-icons}{Those Icons}) whose work served as stems for many of the figures, and the Janet Smith House for the endless support and relentless criticism of the figures. This material is based on work supported by NIH NIDCD R01 DC-015828, NSF Graduate Research Fellowship No. 1309047, and a University of Oregon Incubating Interdisciplinary Initiatives award.} begin by defining the requirements of a complete behavioral system and evaluating two current examples (Sections \ref{sec:existing} and \ref{sec:limitations}). We then describe Autopilot's design principles (Section \ref{sec:design}) and how they are implemented in the program's structure (Section \ref{sec:structure}). We close with a demonstration of its current capabilities and our plans to expand them (Sections \ref{sec:tests} and \ref{sec:future}).
