%!TEX root=../../autopilot.tex

\newthought{Animal behavior} experiments require precision and repetition, which can best be achieved by computer automation. The complexity of contemporary behavioral experiments, however, presents a stiff methodological challenge. For example, researchers might wish to measure pupil dilation\citep{reimerPupilFluctuationsTrack2016, reimerPupilFluctuationsTrack2016}, respiration\citep{parabuckiOdorConcentrationChange2019}, and running speed\citep{niellModulationVisualResponses2010}, while tracking the positions of body parts in 3 dimensions\citep{nathUsingDeepLabCut3D2019} and recording the activity of large ensembles of neurons\citep{junFullyIntegratedSilicon2017}, as subjects perform tasks with custom input devices such as a steering wheel\citep{burgessHighYieldMethodsAccurate2017} while immersed in virtual reality environments using stimuli synthesized in real time\citep{thurleyVirtualRealitySystems2017,chambersOnlineStimulusOptimization2014}. Coordinating the array of necessary hardware into a coherent experimental design---with the millisecond precision required to study the brain---can be daunting.

Historically, researchers have developed software to automate behavior experiments as-needed within their lab or relied on purchasing proprietary software (eg. \citep{elliottNationalInstrumentsLabVIEW2007}). Open-source alternatives have emerged recently, often developed in tandem with hardware peripherals available for purchase \citep{ephysPyControl2019,sandersSanworksBPod}. However, the diverse hardware and software requirements for behavioral experiments often lead researchers to cobble together multiple tools to perform even moderately complex experiments. Understandably, most software packages do not attempt to simultaneously support custom hardware operation, behavioral task logic, stimulus generation, and data acquisition. The difficulty of designing and maintaining lab-idiosyncratic systems thus defines much of the everyday practice of science. Idiosyncratic systems can hinder reproducibility, especially if the level of detail reported in a methods section is sparse\citep{wallReliabilityStartsExperimental2019}. Additionally, development time and proprietary software are expensive, as are the custom hardware peripherals that are required to use most available open-source behavior software, stratifying access to state-of-the-art techniques according to inequitable funding distributions.

Technical challenges are never merely technical: they reflect and are structured by underlying \textit{social} challenges in the organization of scientific labor and knowledge work. Lab infrastructure occupies a space between technology intended for individual users and for large organizations: that of \textit{groupware}\sidenote{"Our original definition of groupware was `intentional group processes plus software to support them.' It has both \textit{computer} and \textit{human} components: software of the computer and `software' of the people using it. [...] Recently this definition has been extended to include other more expressly cultural factors including myth, values and norms. The computer software should reflect and support a groupâ€™s purpose, process and culture."\\Peter and Trudy Johnson-Lenz (1991)\citep{johnson-lenzPostmechanisticGroupwarePrimitives1991}} \citep{johnson-lenzGroupwareCoiningDefining1998,johnson-lenzPostmechanisticGroupwarePrimitives1991}. Experimental frameworks then face the joint challenge of technical competency while also embedding in and supporting existing cultures of practice. Behind every line of code is an unwritten wealth of technical knowledge needed to make use of it, as well as an unspoken set of beliefs about how it is to be used --- labs aren't born fresh on release day ready to retool at a moment's notice, they're held together by decades of duct tape and run on ritual. The boundaries of this "contextual knowledge" extend fluidly beyond individual labs, structuring disciplinary, status, and role systems in scientific work\citep{barleyBackroomsScienceWork1994}. Given their position at the intersection of scientific theory, technical work, data production, and social organization; experimental frameworks are an elusive design challenge: but also an underexplored means of realizing some of our loftier dreams of open, accessible, and collaborative science. 

\vspace{12pt}

Here we present Autopilot, a complete open-source software and hardware framework for behavioral experiments. We leverage the power of distributed computing using the surprisingly capable Raspberry Pi 4\sidenote{See Table \ref{hwtab}} to allow researchers to coordinate arbitrary numbers of heterogeneous hardware components in arbitrary experimental designs.

Autopilot takes a different approach than existing systems to overcome the technical challenges of behavioral research: \textit{just use more computers}. Specifically, the advent of inexpensive single-board computers (ie. the Raspberry Pi) that are powerful enough to run a full Linux operating system allows a unified platform to run on every Pi or other computer in the system so that they can work together seamlessly. At the core of its architecture is a networking protocol (Section \ref{sec:networking}) that is fast enough to stream electrophysiological or imaging data and flexible enough to make the mutual coordination of hardware straightforward. 

This distributed design also makes Autopilot extremely scalable, as the Raspberry Pi's \$35 price tag makes it an order of magnitude less costly than comparable systems (Section \ref{sec:expense}). Its low cost doesn't come at the expense of performance or useability: Autopilot also has an order of magnitude greater measurement precision and an order of magnitude lower latency than comparable systems (Sections \ref{sec:lowlevel} and \ref{sec:tests}).

Autopilot balances experimental flexibility with support. Its task design infrastructure is flexible enough to perform arbitrary experiments, but also provides support for data management, plotting task progress, and custom training regimens. We try to bridge multiple modalities of use: use its modular framework of tools out of the box, or use its \href{https://docs.auto-pi-lot.com}{complete low-level API documentation}\sidenote{\url{https://docs.auto-pi-lot.com}} to hack at it until it does what you need. Rather than relying on costly proprietary hardware modules, users can take advantage of the wide array of peripherals and extensive community support available for the Raspberry Pi. Autopilot is designed to be \textit{permissive}: build your whole experiment with it or just use its networking modules, adapt it to existing hardware, integrate your favorite analysis tool. We want Autopilot to \textit{play nice} with other software libraries and existing practices, rather than forcing you to retool your lab around it.

Finally, we have designed Autopilot to help scientists do reproducible research and be good stewards of the human knowledge project. Experiments are not written as scripts that are reliant on the particularities of each researcher's hardware configuration. Instead, we have designed the system to encourage users to write reusable, portable experiments that can be incorporated into a public central library while also allowing space to iterate and refine without needing to learn complicated programming best-practices to contribute. Every parameter that defines an experiment is automatically saved in  publication-ready format, removing ambiguity in reported methods and facilitating exact replication with a single file. Its plugin system is built atop a densely-linked \href{https://wiki-auto-pi-lot.com}{semantic wiki}\sidenote{\url{https://wiki.auto-pi-lot.com}} that fluidly combines human- and computer-readable, communally editable technical knowledge that surrounds your experiments with the software that performs them.

\vspace{12pt}

We\marginnote{We would like to acknowledge and thank Lucas Ott for doing much of the behavioral training, Brynna Paros and Nick Sattler for their help with constructing our behavioral boxes, Matt Smear and Reese Findley for loaning us their Bpod for far longer than they intended to, Erik Flister whose Ratrix software inspired some of the design features of Autopilot \citep{meierCollinearFeaturesImpair2011}, several artists on \url{flaticon.com} (\href{https://www.flaticon.com/authors/freepik}{Freepik}, \href{https://www.flaticon.com/authors/nikita-golubev}{Nikita Golubev}, \href{https://www.flaticon.com/authors/those-icons}{Those Icons}) whose work served as stems for many of the figures, and the Janet Smith House for the endless support and relentless criticism of the figures. This material is based on work supported by NIH NIDCD R01 DC-015828, NSF Graduate Research Fellowship No. 1309047, and a University of Oregon Incubating Interdisciplinary Initiatives award.} begin by defining the requirements of a complete behavioral system and evaluating two current examples (Sections \ref{sec:existing} and \ref{sec:limitations}). We then describe Autopilot's design principles (Section \ref{sec:design}) and how they are implemented in the program's structure (Section \ref{sec:structure}). We close with a demonstration of its current capabilities and our plans to expand them (Sections \ref{sec:tests} and \ref{sec:future}).
