%!TEX root=../../_preamble.tex
\section{Limitations of Existing Systems}
\label{sec:limitations}

We see several limitations with these and other behavioral systems:

\begin{itemize}[after=\vspace{-\topsep}]
    \item \textbf{Hardware} - Both Pycontrol and Bpod strongly encourage users to purchase a limited set of hardware modules and add-ons from their particular hardware ecosystem. If a required part is not available for purchase, neither system provides a clear means of interacting with custom hardware, requiring the user to 'tack on' loosely-integrated components. There is also a hard limit on the \textit{number} of hardware peripherals that can be used in any given task, as there is no ability to use additional pyboards or Bpod state machines. The microcontrollers used in these systems also impose strong limits on their software: neither run a full, high-level programming language\sidenote{Bpod runs \href{https://github.com/sanworks/Bpod_StateMachine_Firmware}{custom firmware} written in C++ on a \href{https://www.pjrc.com/store/teensy36.html}{Teensy 3.6} microcontroller. pyControl's pyboard implements \href{https://micropython.org/}{micropython}, a subset of Python that excludes canonical libraries like numpy\citep{waltNumPyArrayStructure2011} or scipy\citep{jonesSciPyOpenSource2001}}. We will discuss this further in \hyperref[sec:singlelanguage]{section \ref*{sec:singlelanguage}}. A broader  limitation of existing systems is the difficulty of flexibly integrating the diverse hardware and analytical tools necessary to perform the next generation of behavioral neuroscience experiments that study "naturalistic, unrestrained, and minimally shaped behavior"\citep{dattaComputationalNeuroethologyCall2019}.
    \item \textbf{Stimuli} - Stimuli are not tightly integrated into either of these systems, requiring the user to write custom routines for their synthesis, presentation, and description in the resulting data. Neither are capable of delivering visual stimuli. Since the publication of the initial version of this manuscript, Bpod has added support for the HiFiberry that we also describe here\citep{sanworksllc.ReasonsUseBpod2021}, but the sound generation API appears to be \href{https://github.com/sanworks/Bpod_Gen2/blob/df6cd0c7d5df8247b02077b05fc263f79b86b096/Examples/Protocols/Sound/HiFiSound2AFC_TrialManager/HiFiSound2AFC_TrialManager.m}{unchanged}, with a single method for generating \href{https://github.com/sanworks/Bpod_Gen2/blob/1cb181dffbb7394acd18819f1d268fd9dec6ec5b/Functions/Internal%20Functions/GenerateSineWave.m}{sine waves}. Some parametric audio stimuli are included in the \href{https://bitbucket.org/takam/pycontrol/src/default/pyControl/audio.py}{pyControl source code} but we were unable to find any documentation or examples of their use. %
\end{itemize}\nobreak%
\begin{marginfigure}[0.35cm]
\begin{minted}[frame=lines,fontsize=\small]{matlab}
for currentTrial = 1:MaxTrials
% new state matrix every trial
sma = NewStateMatrix();

% add states and transitions
sma = AddState(sma, 
    'Name', 'Wait', ...
    'Timer', 0,...
    'StateChangeConditions', ...
    {'Port2In', 'Delay'}, ...
    'OutputActions', ...
    {'AudioPlayer1','*'});
% add more states...

% upload and run task
SendStateMatrix(sma);
RawEvents = RunStateMatrix;

% manually gather data and params
BpodSystem.Data = AddTrialEvents(
    BpodSystem.Data, RawEvents);
    
% plotting in the main loop
UpdateSideOutcomePlot(...);
UpdateTotalRewardDisplay(...);

% manually save data
SaveBpodSessionData;
end
\end{minted}
\caption{\href{https://github.com/sanworks/Bpod_Gen2/blob/master/Examples/Protocols/AnalogSound2AFC/AnalogSound2AFC.m}{Bpod's general task structure.}}
\label{fig:bpodtask}
\end{marginfigure}\nobreak
\begin{itemize}[resume*, before=\vspace{0pt}, after=\vspace{\baselineskip}]%
    \item \textbf{Tasks} - Tasks in both systems require a large amount of code and effort duplication. Neither system has a notion of reusable tasks or task 'templates,' so every user needs to rewrite every task from scratch. Bpod's structure in particular tends to encourage users to write long \href{https://github.com/sanworks/Bpod_Gen2/blob/df6cd0c7d5df8247b02077b05fc263f79b86b096/Examples/Protocols/Sound/AnalogSound2AFC/AnalogSound2AFC.m}{task scripts} that are difficult to read (Figure \ref{fig:bpodtask}) because much of its codebase is 'backend' code for compiling and communicating with the state machine, so users have to write basic routines like stimulus creation themselves. Another factor that contributes to the difficulty of task design in these systems is the need to work around the limitations of finite state machines, which we discuss further in section \ref{sec:fsmlimits}.
    \item \textbf{Data} - Data storage and formatting is basic, requiring extensive additional processing to make it human readable. For example, to determine whether a subject got a trial correct in an \href{https://github.com/sanworks/Bpod_Gen2/blob/master/Examples/Protocols/Light/Light2AFC/Light2AFC.m}{example} Bpod experiment, one would use the following code:
    
    \mintinline{matlab}{SessionData.RawEvents.Trial{1,1}.States.Punish(1) ~= NaN}
    
    As a result, data format is idiosyncratic to each user, making data sharing dependent on manual annotation and metadata curation from investigators. 
    \item \textbf{Visualization \& GUI} - The GUIs of each of these systems are highly technical, and are not designed to be easily used by non-programmers, though pyControl's documentation offsets much of this difficulty. Visualization of task progress is quite rigid in both systems, either a timeseries of task states or plots specific to two-alternative forced choice tasks. There is no obvious way to adapt plots to specific tasks.
    \item \textbf{Documentation} - Writing good documentation is challenging, but particularly for infrastructural systems where a user is likely to need to modify it to suit their needs it is important that it be possible to understand its lower-level workings. PyControl has relatively good \href{https://pycontrol.readthedocs.io/en/latest/}{user documentation} for how to use the system, but no API-level documentation. Bpod's \href{https://sites.google.com/site/bpoddocumentation/home}{documentation} is a bit more scattered, and though it does have documentation for a \href{https://sites.google.com/site/bpoddocumentation/user-guide/function-reference}{subset of its functions}, there is little indication of how they work together or how someone might be able to modify them.
    \item \textbf{Reproducibility} - As of \href{https://github.com/pyControl/code/blob/cc6e7ab67c18388dea85b3ac48ac66a65ffa12f8/ChangeLog.txt#L74}{November 2020}, pyControl has \href{https://pycontrol.readthedocs.io/en/latest/user-guide/pycontrol-data/#versioned-task-files}{versioned task files} that append a hash to each version of a task and save it along with any produced data. PyControl's most recent releases have explicit \href{https://github.com/pyControl/code/releases}{version numbers}, but these don't appear to be saved along with the data. Bpod stores neither code nor task versions in its data. Neither system saves experimental parameter changes by default ---and the GUIs of both allow parameters to be changed at will--- and so critical data could be lost and experiments made unreproducible unless the user writes custom code to save them. Bpod has an undocumented \href{https://github.com/sanworks/Bpod_Gen2/commit/10ad997555086afb93dfc1080091acaa58d740f9}{plugin system}, but neither system has a formal system for sharing plugins or task code, requiring work to be duplicated across all users of the system.
    \item \textbf{Integration and Extension} - Integration with other systems that might handle some out-of-scope function is tricky in both of these example systems. All systems have some limitation, so care must be taken to provide points by which other systems might interact with them. One particularly potent example is the use of Bpod in the International Brain Laboratory's standardized experimental rig\citep{laboratoryStandardizedReproducibleMeasurement2020b}, which relies on a single-purpose \href{https://figshare.com/articles/preprint/A_standardized_and_reproducible_method_to_measure_decision-making_in_mice_Appendix_3_IBL_protocol_for_setting_up_the_behavioral_training_rig/11634732}{93 page PDF} to describe how to use the \href{https://github.com/int-brain-lab/iblrig}{iblrig} library, which consists of a large amount of single-purpose code for stitching together pybpod with \href{https://github.com/int-brain-lab/iblrig/blob/18569278fc2d8cd3266adb2a5f660a43f8f2582e/iblrig/bonsai.py}{bonsai} for controlling video acquisition. Even if a system takes that amount of additional work to integrate with another, hopefully the system allows it to be done in a way such that it can be reused and shared with others in the future so they can be spared the trouble. The relatively sparse \href{https://iblrig.readthedocs.io/en/latest/index.html}{documentation} and the high proportion of ibl-specific code present in the repository make that seem unlikely.
\end{itemize}

Some of these limitations are cosmetic---fixable with additional code or hardware---but several of the most crucial are intrinsic to the design of these systems.

These systems, among others, have pioneered the development of modern behavioral hardware and software, and are to be commended for being open-source and highly functional. One need look no further for evidence of their usefulness than to their adoption by many labs worldwide. At the time that these systems were developed, a general-purpose single-board computer with performance like the Raspberry Pi 4 was not widely available. The above two systems are not unique in their limitations\marginnote{And Autopilot, of course, also has many of its own weaknesses}, but are reflective of broader constraints of developing experimental tools. We are only able to articulate the design principles that differentiate Autopilot by building on their work. 
